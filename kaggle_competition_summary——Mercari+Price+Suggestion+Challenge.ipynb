{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于Mercari Price Suggestion Challenge比赛的总结（一）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在工作之余时间和一些小伙伴一起参加了kaggle的比赛（工作的时候能真正投入到比赛的时间真的很少，所以学习了一些kernel的作品），虽然fork了其他人的作品，但跑完仔细分析了下收货不小。另外，这次比赛非常重要的一点是对时间的限制，一个小时的时间要完成所有的步骤！！（这也是让我们小伙伴比较棘手的一点，想调参或者上其他训练时间耗费更多的复杂模型你就需要做一个trade-off）。还有比赛也不能拿比赛中的数据来训练word2vec模型，这一点也很重要。但可以拿公开的word2vec模型。比如Facebook的[fasttext](https://github.com/facebookresearch/fastText \"fasttext\")~\n",
    "\n",
    "趁着过年一点闲暇时间总结一番，我觉得重要的不是刷名次，而是沉淀一些Feature Engineering tricks和Algorithm.（捂脸，主要是想懒得炼丹调参了。另外主要也是想趁过年这段时间总结下去年一年所做过的项目）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这篇主要是利用RNN and Ridge model来做predict，最后的public score是0.42688"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这场比赛提供的数据很有意思，既有文本类的数据，也有数值类型的数据，这些数据一起组合成了结构化的表数据。然后提供给参赛者，看如何通过特征的组合变化来融合成一个强大的特征~\n",
    "首先简单分析下每个字段的数据，直接附上官方的数据说明。很容易明白里面的含义~\n",
    "\n",
    "The files consist of a list of product listings. These files are tab-delimited.\n",
    "- train_id or test_id - the id of the listing\n",
    "- name - the title of the listing. Note that we have cleaned the data to remove text that look like prices (e.g. 20 dollar ) to avoid leakage. These removed prices are represented as [rm]\n",
    "- item_condition_id - the condition of the items provided by the seller\n",
    "- category_name - category of the listing\n",
    "- brand_name\n",
    "- price - the price that the item was sold for. This is the target variable that you will predict. The unit is USD. This column doesn't exist in test.tsv since that is what you will predict.\n",
    "- shipping - 1 if shipping fee is paid by seller and 0 by buyer\n",
    "- item_description - the full description of the item. Note that we have cleaned the data to remove text that look like prices (e.g. 20 dollar) to avoid leakage. These removed prices are represented as [rm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "##Import all needed packages for constructing models and solving the competition\n",
    "from datetime import datetime \n",
    "start_real = datetime.now()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, concatenate, GRU, Embedding, Flatten, Activation\n",
    "# from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "# set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义rmsl误差函数（这里的Y和Y_pred都取了对数，因为真实的Y不是正态分布）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define RMSL Error Function\n",
    "##This is for checking the predictions at the end. Note that the Y and Y_pred will already be in log scale by the time this is used, so no need to log them in the function.\n",
    "def rmsle(Y, Y_pred):\n",
    "    assert Y.shape == Y_pred.shape\n",
    "    return np.sqrt(np.mean(np.square(Y_pred - Y )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482535, 8) (693359, 7)\n"
     ]
    }
   ],
   "source": [
    "#Load train and test data\n",
    "train_df = pd.read_table('F:\\kaggle\\MercariPrice/train.tsv')\n",
    "test_df = pd.read_table('F:\\kaggle\\MercariPrice/test.tsv')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里为了测试方便，按照2:1的比例来取train和test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8) (1000, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[:2000]\n",
    "test_df = test_df[:1000]\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理——去除低prices：Mercari任何低于3美元的商品都不会允许在平台上发布。所以列表中出现低于3美元的物品都要remove掉！这样对最后的模型有利。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 8)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理——去除停用词.但是这一步并没有参与执行！这是因为模型对停用词有很强的鲁棒性，虽然去除停用词对模型有一个小的提升，但是基于严格的时间限制，不值得花费1-2分钟运行这个块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# stop = stopwords.words('english')\n",
    "# train_df.item_description.fillna(value='No description yet', inplace=True)\n",
    "# train_df['item_description'] = train_df['item_description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "# train_df.name.fillna(value=\"missing\", inplace=True)\n",
    "# train_df['name'] = train_df['name'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# test_df.item_description.fillna(value='No description yet', inplace=True)\n",
    "# test_df['item_description'] = test_df['item_description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "# test_df.name.fillna(value=\"missing\", inplace=True)\n",
    "# test_df['name'] = test_df['name'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理——item_description字段描述的长度，即描述所使用的单词的原始数量，与价格有一定的相关性。The RNN might find this out on it's own, but since a max depth is used to save computations, it does not always know.\n",
    "描述长度明显有助于模型，但name字段的长度可能不是会影响那么多。因为name的长度对模型也不会降低模型性能，因此也可留下名字长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>name_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  desc_len  \\\n",
       "0         1                                 No description yet         0   \n",
       "1         0  This keyboard is in great condition and works ...        36   \n",
       "2         1  Adorable top with a hint of lace and a key hol...        29   \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...        32   \n",
       "4         0          Complete with certificate of authenticity         5   \n",
       "\n",
       "   name_len  \n",
       "0         7  \n",
       "1         4  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get name and description lengths\n",
    "def wordCount(text):\n",
    "    try:\n",
    "        if text == 'No description yet':\n",
    "            return 0\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            words = [w for w in text.split(\" \")]\n",
    "            return len(words)\n",
    "    except: \n",
    "        return 0\n",
    "train_df['desc_len'] = train_df['item_description'].apply(lambda x: wordCount(x))\n",
    "test_df['desc_len'] = test_df['item_description'].apply(lambda x: wordCount(x))\n",
    "train_df['name_len'] = train_df['name'].apply(lambda x: wordCount(x))\n",
    "test_df['name_len'] = test_df['name'].apply(lambda x: wordCount(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理——将category_name字段split成三个parts这样使得模型可以获取更多的信息。\n",
    "I tried making a small 3 part RNN layer for this instead which does worse than this method but is occasionally faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split category name into 3 parts\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "train_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] = \\\n",
    "zip(*train_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "test_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n",
    "zip(*test_df['category_name'].apply(lambda x: split_cat(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>name_len</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computers &amp; Tablets</td>\n",
       "      <td>Components &amp; Parts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; Blouses</td>\n",
       "      <td>Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home Décor</td>\n",
       "      <td>Home Décor Accents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Necklaces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  desc_len  \\\n",
       "0         1                                 No description yet         0   \n",
       "1         0  This keyboard is in great condition and works ...        36   \n",
       "2         1  Adorable top with a hint of lace and a key hol...        29   \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...        32   \n",
       "4         0          Complete with certificate of authenticity         5   \n",
       "\n",
       "   name_len     subcat_0             subcat_1            subcat_2  \n",
       "0         7          Men                 Tops            T-shirts  \n",
       "1         4  Electronics  Computers & Tablets  Components & Parts  \n",
       "2         2        Women       Tops & Blouses              Blouse  \n",
       "3         3         Home           Home Décor  Home Décor Accents  \n",
       "4         4        Women              Jewelry           Necklaces  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1999 entries, 0 to 1999\n",
      "Data columns (total 13 columns):\n",
      "train_id             1999 non-null int64\n",
      "name                 1999 non-null object\n",
      "item_condition_id    1999 non-null int64\n",
      "category_name        1988 non-null object\n",
      "brand_name           1158 non-null object\n",
      "price                1999 non-null float64\n",
      "shipping             1999 non-null int64\n",
      "item_description     1999 non-null object\n",
      "desc_len             1999 non-null int64\n",
      "name_len             1999 non-null int64\n",
      "subcat_0             1999 non-null object\n",
      "subcat_1             1999 non-null object\n",
      "subcat_2             1999 non-null object\n",
      "dtypes: float64(1), int64(5), object(7)\n",
      "memory usage: 218.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理——缺失值填充。\n",
    "##The brand name data is sparse, missing over 600,000 values. This gets some of those values back by checking their names. However, It does not seem to help the models either way at this point. An exact name match against all_brand names will find about 3000 of these. We can be pretty confident in these. At the other extreme, we can search for any matches throughout all words in name. This finds over 200,000 but a lot of these are incorrect. Can land somewhere in the middle by either keeping cases or trimming out some of the 5000 brand names.\n",
    "##For example, PINK is a brand by victoria secret. If we remove case, then almost all pink items are labeled as PINK brand. The other issue is that some of the \"brand names\" are not brands but really categories like \"Boots\" or \"Keys\".\n",
    "##Currently, checking every word in name of a case-sensitive match does best. This gets around 137,000 finds while avoiding the problems with brands like PINK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_set = pd.concat([train_df,test_df])\n",
    "all_brands = set(full_set['brand_name'].values)\n",
    "train_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "test_df.brand_name.fillna(value=\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "# get to finding!\n",
    "premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "def brandfinder(line):\n",
    "    brand = line[0]\n",
    "    name = line[1]\n",
    "    namesplit = name.split(' ')\n",
    "    if brand == 'missing':\n",
    "        for x in namesplit:\n",
    "            if x in all_brands:\n",
    "                return name\n",
    "    if name in all_brands:\n",
    "        return name\n",
    "    return brand\n",
    "train_df['brand_name'] = train_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "test_df['brand_name'] = test_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "found = premissing-len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>name_len</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computers &amp; Tablets</td>\n",
       "      <td>Components &amp; Parts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; Blouses</td>\n",
       "      <td>Blouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "\n",
       "                                       category_name  \\\n",
       "0                                  Men/Tops/T-shirts   \n",
       "1  Electronics/Computers & Tablets/Components & P...   \n",
       "2                        Women/Tops & Blouses/Blouse   \n",
       "\n",
       "                            brand_name  price  shipping  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL   10.0         1   \n",
       "1                                Razer   52.0         0   \n",
       "2                               Target   10.0         1   \n",
       "\n",
       "                                    item_description  desc_len  name_len  \\\n",
       "0                                 No description yet         0         7   \n",
       "1  This keyboard is in great condition and works ...        36         4   \n",
       "2  Adorable top with a hint of lace and a key hol...        29         2   \n",
       "\n",
       "      subcat_0             subcat_1            subcat_2  \n",
       "0          Men                 Tops            T-shirts  \n",
       "1  Electronics  Computers & Tablets  Components & Parts  \n",
       "2        Women       Tops & Blouses              Blouse  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1979 examples\n",
      "Validating on 20 examples\n",
      "Testing on 1000 examples\n"
     ]
    }
   ],
   "source": [
    "##Standard split the train test for validation and log the price\n",
    "\n",
    "# Scale target variable to log.\n",
    "train_df[\"target\"] = np.log1p(train_df.price)\n",
    "\n",
    "# Split training examples into train/dev examples.\n",
    "train_df, dev_df = train_test_split(train_df, random_state=123, train_size=0.99)\n",
    "\n",
    "# Calculate number of train/dev/test examples.\n",
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "n_tests = test_df.shape[0]\n",
    "print(\"Training on\", n_trains, \"examples\")\n",
    "print(\"Validating on\", n_devs, \"examples\")\n",
    "print(\"Testing on\", n_tests, \"examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用RNN模型来解决问题，有以下几个步骤：\n",
    "- 预处理数据\n",
    "- 定义RNN模型\n",
    "- 用RNN模型拟合训练集样本\n",
    "- 在验证集上评估RNN模型\n",
    "- 用RNN模型对测试集进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 拼接 train - dev - test data以方便处理\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2999 entries, 1503 to 999\n",
      "Data columns (total 15 columns):\n",
      "brand_name           2999 non-null object\n",
      "category_name        2985 non-null object\n",
      "desc_len             2999 non-null int64\n",
      "item_condition_id    2999 non-null int64\n",
      "item_description     2999 non-null object\n",
      "name                 2999 non-null object\n",
      "name_len             2999 non-null int64\n",
      "price                1999 non-null float64\n",
      "shipping             2999 non-null int64\n",
      "subcat_0             2999 non-null object\n",
      "subcat_1             2999 non-null object\n",
      "subcat_2             2999 non-null object\n",
      "target               1999 non-null float64\n",
      "test_id              1000 non-null float64\n",
      "train_id             1999 non-null float64\n",
      "dtypes: float64(4), int64(4), object(7)\n",
      "memory usage: 374.9+ KB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing data...\n",
      "1    Electronics/Computers & Tablets/Components & P...\n",
      "1              Other/Office supplies/Shipping Supplies\n",
      "Name: category_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#填充缺失值（NA值），用“missing”来替换“No description yet”以提升模型！\n",
    "# Filling missing values\n",
    "def fill_missing_values(df):\n",
    "    df.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.replace('No description yet',\"missing\", inplace=True)\n",
    "    return df\n",
    "\n",
    "print(\"Filling missing data...\")\n",
    "full_df = fill_missing_values(full_df)\n",
    "print(full_df.category_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>name_len</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>target</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Home/Home Appliances/Vacuums &amp; Floor Care</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Hoover Air Express Handheld Vacuum w...</td>\n",
       "      <td>Hoover Air Express Hand Vacuum</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home Appliances</td>\n",
       "      <td>Vacuums &amp; Floor Care</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Old Navy</td>\n",
       "      <td>Kids/Girls 0-24 Mos/One-Pieces</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirt 0-3 month leggings 6 months old navy and...</td>\n",
       "      <td>Winter bundle</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Girls 0-24 Mos</td>\n",
       "      <td>One-Pieces</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>American Boy &amp; Girl</td>\n",
       "      <td>Kids/Toys/Dolls &amp; Accessories</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Theater case/ Trunk with box.</td>\n",
       "      <td>Marisol Lot HOLD APPLE</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Dolls &amp; Accessories</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand_name                              category_name  \\\n",
       "1503               Hoover  Home/Home Appliances/Vacuums & Floor Care   \n",
       "553              Old Navy             Kids/Girls 0-24 Mos/One-Pieces   \n",
       "775   American Boy & Girl              Kids/Toys/Dolls & Accessories   \n",
       "\n",
       "      desc_len  item_condition_id  \\\n",
       "1503        35                  1   \n",
       "553         10                  2   \n",
       "775          5                  2   \n",
       "\n",
       "                                       item_description  \\\n",
       "1503  Brand New Hoover Air Express Handheld Vacuum w...   \n",
       "553   Shirt 0-3 month leggings 6 months old navy and...   \n",
       "775                       Theater case/ Trunk with box.   \n",
       "\n",
       "                                name  name_len  price  shipping subcat_0  \\\n",
       "1503  Hoover Air Express Hand Vacuum         5   12.0         1     Home   \n",
       "553                    Winter bundle         2    8.0         0     Kids   \n",
       "775           Marisol Lot HOLD APPLE         4   29.0         0     Kids   \n",
       "\n",
       "             subcat_1              subcat_2    target  test_id  train_id  \n",
       "1503  Home Appliances  Vacuums & Floor Care  2.564949      NaN    1503.0  \n",
       "553    Girls 0-24 Mos            One-Pieces  2.197225      NaN     553.0  \n",
       "775              Toys   Dolls & Accessories  3.401197      NaN     775.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2999 entries, 1503 to 999\n",
      "Data columns (total 15 columns):\n",
      "brand_name           2999 non-null object\n",
      "category_name        2999 non-null object\n",
      "desc_len             2999 non-null int64\n",
      "item_condition_id    2999 non-null int64\n",
      "item_description     2999 non-null object\n",
      "name                 2999 non-null object\n",
      "name_len             2999 non-null int64\n",
      "price                1999 non-null float64\n",
      "shipping             2999 non-null int64\n",
      "subcat_0             2999 non-null object\n",
      "subcat_1             2999 non-null object\n",
      "subcat_2             2999 non-null object\n",
      "target               1999 non-null float64\n",
      "test_id              1000 non-null float64\n",
      "train_id             1999 non-null float64\n",
      "dtypes: float64(4), int64(4), object(7)\n",
      "memory usage: 454.9+ KB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理类别型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing categorical data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Processing categorical data...\")\n",
    "le = LabelEncoder()\n",
    "# full_df.category = full_df.category_name\n",
    "le.fit(full_df.category_name)\n",
    "full_df['category'] = le.transform(full_df.category_name)\n",
    "\n",
    "le.fit(full_df.brand_name)\n",
    "full_df.brand_name = le.transform(full_df.brand_name)\n",
    "\n",
    "le.fit(full_df.subcat_0)\n",
    "full_df.subcat_0 = le.transform(full_df.subcat_0)\n",
    "\n",
    "le.fit(full_df.subcat_1)\n",
    "full_df.subcat_1 = le.transform(full_df.subcat_1)\n",
    "\n",
    "le.fit(full_df.subcat_2)\n",
    "full_df.subcat_2 = le.transform(full_df.subcat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>name_len</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>target</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>200</td>\n",
       "      <td>Home/Home Appliances/Vacuums &amp; Floor Care</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Hoover Air Express Handheld Vacuum w...</td>\n",
       "      <td>Hoover Air Express Hand Vacuum</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>318</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>354</td>\n",
       "      <td>Kids/Girls 0-24 Mos/One-Pieces</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirt 0-3 month leggings 6 months old navy and...</td>\n",
       "      <td>Winter bundle</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>222</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553.0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>32</td>\n",
       "      <td>Kids/Toys/Dolls &amp; Accessories</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Theater case/ Trunk with box.</td>\n",
       "      <td>Marisol Lot HOLD APPLE</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>109</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_name                              category_name  desc_len  \\\n",
       "1503         200  Home/Home Appliances/Vacuums & Floor Care        35   \n",
       "553          354             Kids/Girls 0-24 Mos/One-Pieces        10   \n",
       "775           32              Kids/Toys/Dolls & Accessories         5   \n",
       "\n",
       "      item_condition_id                                   item_description  \\\n",
       "1503                  1  Brand New Hoover Air Express Handheld Vacuum w...   \n",
       "553                   2  Shirt 0-3 month leggings 6 months old navy and...   \n",
       "775                   2                      Theater case/ Trunk with box.   \n",
       "\n",
       "                                name  name_len  price  shipping  subcat_0  \\\n",
       "1503  Hoover Air Express Hand Vacuum         5   12.0         1         3   \n",
       "553                    Winter bundle         2    8.0         0         4   \n",
       "775           Marisol Lot HOLD APPLE         4   29.0         0         4   \n",
       "\n",
       "      subcat_1  subcat_2    target  test_id  train_id  category  \n",
       "1503        44       318  2.564949      NaN    1503.0       103  \n",
       "553         38       222  2.197225      NaN     553.0       171  \n",
       "775         86       109  3.401197      NaN     775.0       192  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>name_len</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>target</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>200</td>\n",
       "      <td>Home/Home Appliances/Vacuums &amp; Floor Care</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Hoover Air Express Handheld Vacuum w...</td>\n",
       "      <td>Hoover Air Express Hand Vacuum</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>318</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>354</td>\n",
       "      <td>Kids/Girls 0-24 Mos/One-Pieces</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirt 0-3 month leggings 6 months old navy and...</td>\n",
       "      <td>Winter bundle</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>222</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553.0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>32</td>\n",
       "      <td>Kids/Toys/Dolls &amp; Accessories</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Theater case/ Trunk with box.</td>\n",
       "      <td>Marisol Lot HOLD APPLE</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>109</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_name                              category_name  desc_len  \\\n",
       "1503         200  Home/Home Appliances/Vacuums & Floor Care        35   \n",
       "553          354             Kids/Girls 0-24 Mos/One-Pieces        10   \n",
       "775           32              Kids/Toys/Dolls & Accessories         5   \n",
       "\n",
       "      item_condition_id                                   item_description  \\\n",
       "1503                  1  Brand New Hoover Air Express Handheld Vacuum w...   \n",
       "553                   2  Shirt 0-3 month leggings 6 months old navy and...   \n",
       "775                   2                      Theater case/ Trunk with box.   \n",
       "\n",
       "                                name  name_len  price  shipping  subcat_0  \\\n",
       "1503  Hoover Air Express Hand Vacuum         5   12.0         1         3   \n",
       "553                    Winter bundle         2    8.0         0         4   \n",
       "775           Marisol Lot HOLD APPLE         4   29.0         0         4   \n",
       "\n",
       "      subcat_1  subcat_2    target  test_id  train_id  category  \n",
       "1503        44       318  2.564949      NaN    1503.0       103  \n",
       "553         38       222  2.197225      NaN     553.0       171  \n",
       "775         86       109  3.401197      NaN     775.0       192  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理文本型特征，将文本数据转换成序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming text data to sequences...\n",
      "   Fitting tokenizer...\n",
      "   Transforming text to sequences...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming text data to sequences...\")\n",
    "raw_text = np.hstack([full_df.item_description.str.lower(), full_df.name.str.lower(), full_df.category_name.str.lower()])\n",
    "\n",
    "print(\"   Fitting tokenizer...\")\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "print(\"   Transforming text to sequences...\")\n",
    "full_df['seq_item_description'] = tok_raw.texts_to_sequences(full_df.item_description.str.lower())\n",
    "full_df['seq_name'] = tok_raw.texts_to_sequences(full_df.name.str.lower())\n",
    "full_df['seq_category'] = tok_raw.texts_to_sequences(full_df.category_name.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503    [3817, 520, 1182, 412, 1761]\n",
      "553                        [485, 29]\n",
      "775            [8977, 206, 321, 401]\n",
      "918        [98, 280, 8978, 8979, 57]\n",
      "1297        [30, 50, 2259, 371, 738]\n",
      "Name: seq_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "del tok_raw\n",
    "\n",
    "print(full_df['seq_name'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>name_len</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>target</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>category</th>\n",
       "      <th>seq_item_description</th>\n",
       "      <th>seq_name</th>\n",
       "      <th>seq_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>200</td>\n",
       "      <td>Home/Home Appliances/Vacuums &amp; Floor Care</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Hoover Air Express Handheld Vacuum w...</td>\n",
       "      <td>Hoover Air Express Hand Vacuum</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>318</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>103</td>\n",
       "      <td>[17, 6, 3817, 520, 1182, 3003, 1761, 9, 5400, ...</td>\n",
       "      <td>[3817, 520, 1182, 412, 1761]</td>\n",
       "      <td>[36, 36, 1594, 9938, 2784, 128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>354</td>\n",
       "      <td>Kids/Girls 0-24 Mos/One-Pieces</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirt 0-3 month leggings 6 months old navy and...</td>\n",
       "      <td>Winter bundle</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>222</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553.0</td>\n",
       "      <td>171</td>\n",
       "      <td>[103, 133, 38, 424, 57, 50, 451, 502, 244, 1, ...</td>\n",
       "      <td>[485, 29]</td>\n",
       "      <td>[33, 97, 133, 140, 224, 52, 379]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>32</td>\n",
       "      <td>Kids/Toys/Dolls &amp; Accessories</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Theater case/ Trunk with box.</td>\n",
       "      <td>Marisol Lot HOLD APPLE</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>109</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "      <td>192</td>\n",
       "      <td>[5403, 129, 5404, 9, 67]</td>\n",
       "      <td>[8977, 206, 321, 401]</td>\n",
       "      <td>[33, 160, 443, 26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>207</td>\n",
       "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new with tags. Black background with tan...</td>\n",
       "      <td>Lularoe OS peeking Santa leggings.</td>\n",
       "      <td>5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>231</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>918.0</td>\n",
       "      <td>323</td>\n",
       "      <td>[17, 6, 9, 87, 28, 826, 9, 654, 418, 1021, 221...</td>\n",
       "      <td>[98, 280, 8978, 8979, 57]</td>\n",
       "      <td>[3, 45, 59, 64, 132, 57]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_name                                   category_name  desc_len  \\\n",
       "1503         200       Home/Home Appliances/Vacuums & Floor Care        35   \n",
       "553          354                  Kids/Girls 0-24 Mos/One-Pieces        10   \n",
       "775           32                   Kids/Toys/Dolls & Accessories         5   \n",
       "918          207  Women/Athletic Apparel/Pants, Tights, Leggings        12   \n",
       "\n",
       "      item_condition_id                                   item_description  \\\n",
       "1503                  1  Brand New Hoover Air Express Handheld Vacuum w...   \n",
       "553                   2  Shirt 0-3 month leggings 6 months old navy and...   \n",
       "775                   2                      Theater case/ Trunk with box.   \n",
       "918                   1  Brand new with tags. Black background with tan...   \n",
       "\n",
       "                                    name  name_len  price  shipping  subcat_0  \\\n",
       "1503      Hoover Air Express Hand Vacuum         5   12.0         1         3   \n",
       "553                        Winter bundle         2    8.0         0         4   \n",
       "775               Marisol Lot HOLD APPLE         4   29.0         0         4   \n",
       "918   Lularoe OS peeking Santa leggings.         5   44.0         0        10   \n",
       "\n",
       "      subcat_1  subcat_2    target  test_id  train_id  category  \\\n",
       "1503        44       318  2.564949      NaN    1503.0       103   \n",
       "553         38       222  2.197225      NaN     553.0       171   \n",
       "775         86       109  3.401197      NaN     775.0       192   \n",
       "918          5       231  3.806662      NaN     918.0       323   \n",
       "\n",
       "                                   seq_item_description  \\\n",
       "1503  [17, 6, 3817, 520, 1182, 3003, 1761, 9, 5400, ...   \n",
       "553   [103, 133, 38, 424, 57, 50, 451, 502, 244, 1, ...   \n",
       "775                            [5403, 129, 5404, 9, 67]   \n",
       "918   [17, 6, 9, 87, 28, 826, 9, 654, 418, 1021, 221...   \n",
       "\n",
       "                          seq_name                      seq_category  \n",
       "1503  [3817, 520, 1182, 412, 1761]   [36, 36, 1594, 9938, 2784, 128]  \n",
       "553                      [485, 29]  [33, 97, 133, 140, 224, 52, 379]  \n",
       "775          [8977, 206, 321, 401]                [33, 160, 443, 26]  \n",
       "918      [98, 280, 8978, 8979, 57]          [3, 45, 59, 64, 132, 57]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义一些常量；注意，前几行旁边的注释表示该列中的最长条目。 \n",
    "MAX_NAME_SEQ = 10 #17\n",
    "MAX_ITEM_DESC_SEQ = 75 #269\n",
    "MAX_CATEGORY_SEQ = 8 #8\n",
    "MAX_TEXT = np.max([\n",
    "    np.max(full_df.seq_name.max()),\n",
    "    np.max(full_df.seq_item_description.max()),\n",
    "#     np.max(full_df.seq_category.max()),\n",
    "]) + 100\n",
    "MAX_CATEGORY = np.max(full_df.category.max()) + 1\n",
    "MAX_BRAND = np.max(full_df.brand_name.max()) + 1\n",
    "MAX_CONDITION = np.max(full_df.item_condition_id.max()) + 1\n",
    "MAX_DESC_LEN = np.max(full_df.desc_len.max()) + 1\n",
    "MAX_NAME_LEN = np.max(full_df.name_len.max()) + 1\n",
    "MAX_SUBCAT_0 = np.max(full_df.subcat_0.max()) + 1\n",
    "MAX_SUBCAT_1 = np.max(full_df.subcat_1.max()) + 1\n",
    "MAX_SUBCAT_2 = np.max(full_df.subcat_2.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(full_df.subcat_2.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get data for RNN model\n",
    "def get_rnn_data(dataset):\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ),\n",
    "        'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ),\n",
    "        'brand_name': np.array(dataset.brand_name),\n",
    "        'category': np.array(dataset.category),\n",
    "#         'category_name': pad_sequences(dataset.seq_category, maxlen=MAX_CATEGORY_SEQ),\n",
    "        'item_condition': np.array(dataset.item_condition_id),\n",
    "        'num_vars': np.array(dataset[[\"shipping\"]]),\n",
    "        'desc_len': np.array(dataset[[\"desc_len\"]]),\n",
    "        'name_len': np.array(dataset[[\"name_len\"]]),\n",
    "        'subcat_0': np.array(dataset.subcat_0),\n",
    "        'subcat_1': np.array(dataset.subcat_1),\n",
    "        'subcat_2': np.array(dataset.subcat_2),\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ list([17, 6, 3817, 520, 1182, 3003, 1761, 9, 5400, 1, 1949, 8, 5401, 1104, 49, 39, 27, 1761, 113, 869, 2538, 19, 11, 547, 19, 172, 85, 4, 63, 5402, 653, 243, 371, 178, 381, 15])\n",
      " list([103, 133, 38, 424, 57, 50, 451, 502, 244, 1, 1950])\n",
      " list([5403, 129, 5404, 9, 67]) ..., list([39, 52, 257, 166, 80, 87])\n",
      " list([448, 16, 185, 10, 448, 16, 188])\n",
      " list([167, 365, 206, 12, 5318, 5319, 396])]\n",
      "[[   0    0    0 ...,  178  381   15]\n",
      " [   0    0    0 ...,  244    1 1950]\n",
      " [   0    0    0 ..., 5404    9   67]\n",
      " ..., \n",
      " [   0    0    0 ...,  166   80   87]\n",
      " [   0    0    0 ...,  448   16  188]\n",
      " [   0    0    0 ..., 5318 5319  396]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(full_df.seq_item_description))\n",
    "print(pad_sequences(full_df.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将数据转换成rnn模型所需的数据形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = full_df[:n_trains]\n",
    "dev = full_df[n_trains:n_trains+n_devs]\n",
    "test = full_df[n_trains+n_devs:]\n",
    "\n",
    "X_train = get_rnn_data(train)\n",
    "Y_train = train.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = get_rnn_data(dev)\n",
    "Y_dev = dev.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = get_rnn_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand_name': array([200, 354,  32, ...,  78, 505, 389], dtype=int64),\n",
       " 'category': array([103, 171, 192, ..., 339, 353, 325], dtype=int64),\n",
       " 'desc_len': array([[35],\n",
       "        [10],\n",
       "        [ 5],\n",
       "        ..., \n",
       "        [ 0],\n",
       "        [ 9],\n",
       "        [41]], dtype=int64),\n",
       " 'item_condition': array([1, 2, 2, ..., 2, 1, 2], dtype=int64),\n",
       " 'item_desc': array([[   0,    0,    0, ...,  178,  381,   15],\n",
       "        [   0,    0,    0, ...,  244,    1, 1950],\n",
       "        [   0,    0,    0, ..., 5404,    9,   67],\n",
       "        ..., \n",
       "        [   0,    0,    0, ...,    0,    0,   77],\n",
       "        [   0,    0,    0, ...,   89,  233,  106],\n",
       "        [   0,    0,    0, ...,    5, 1330,   71]]),\n",
       " 'name': array([[   0,    0,    0, ..., 1182,  412, 1761],\n",
       "        [   0,    0,    0, ...,    0,  485,   29],\n",
       "        [   0,    0,    0, ...,  206,  321,  401],\n",
       "        ..., \n",
       "        [   0,    0,    0, ...,  623, 4066,   93],\n",
       "        [   0,    0,    0, ...,    0,  548,  390],\n",
       "        [   0,    0,    0, ...,  122,    7,  487]]),\n",
       " 'name_len': array([[5],\n",
       "        [2],\n",
       "        [4],\n",
       "        ..., \n",
       "        [4],\n",
       "        [2],\n",
       "        [5]], dtype=int64),\n",
       " 'num_vars': array([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        ..., \n",
       "        [1],\n",
       "        [0],\n",
       "        [0]], dtype=int64),\n",
       " 'subcat_0': array([ 3,  4,  4, ..., 10, 10, 10], dtype=int64),\n",
       " 'subcat_1': array([44, 38, 86, ..., 27, 48,  5], dtype=int64),\n",
       " 'subcat_2': array([318, 222, 109, ...,   1,  42, 270], dtype=int64)}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"name\"].shape\n",
    "X_train[\"num_vars\"].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1979,)\n",
      "(1979, 1)\n",
      "(1979, 75)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(X_train['subcat_2'].shape)\n",
    "print(X_train['desc_len'].shape)\n",
    "print(X_train['item_desc'].shape)\n",
    "print(X_train['name'].shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "brand_name (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "item_condition (InputLayer)      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "desc_len (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "name_len (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "subcat_0 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "subcat_1 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "subcat_2 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "item_desc (InputLayer)           (None, 75)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "name (InputLayer)                (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)         (None, 1, 10)         5090        brand_name[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)         (None, 1, 5)          30          item_condition[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)         (None, 1, 5)          1090        desc_len[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)         (None, 1, 5)          55          name_len[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)         (None, 1, 10)         110         subcat_0[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)         (None, 1, 10)         940         subcat_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)         (None, 1, 10)         3350        subcat_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)         (None, 75, 60)        602220      item_desc[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)         (None, 10, 20)        200740      name[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 10)            0           embedding_21[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 5)             0           embedding_22[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 5)             0           embedding_23[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 5)             0           embedding_24[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)             (None, 10)            0           embedding_25[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)             (None, 10)            0           embedding_26[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 10)            0           embedding_27[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "gru_5 (GRU)                      (None, 16)            3696        embedding_20[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "gru_6 (GRU)                      (None, 8)             696         embedding_19[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "num_vars (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 80)            0           flatten_15[0][0]                 \n",
      "                                                                   flatten_16[0][0]                 \n",
      "                                                                   flatten_17[0][0]                 \n",
      "                                                                   flatten_18[0][0]                 \n",
      "                                                                   flatten_19[0][0]                 \n",
      "                                                                   flatten_20[0][0]                 \n",
      "                                                                   flatten_21[0][0]                 \n",
      "                                                                   gru_5[0][0]                      \n",
      "                                                                   gru_6[0][0]                      \n",
      "                                                                   num_vars[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 512)           41472       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 512)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 256)           131328      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 256)           0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 128)           32896       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 128)           0           dense_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 64)            8256        dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 64)            0           dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 1)             65          dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,032,034\n",
      "Trainable params: 1,032,034\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##Now to build the model. Old category stuff is commented out but left in case of revist. (other adjustment notes in comments)\n",
    "# set seed again in case testing models adjustments by looping next 2 blocks\n",
    "np.random.seed(123)\n",
    "def new_rnn_model(lr=0.001, decay=0.0):\n",
    "    # Inputs\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "#     category = Input(shape=[1], name=\"category\")\n",
    "#     category_name = Input(shape=[X_train[\"category_name\"].shape[1]], name=\"category_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    desc_len = Input(shape=[1], name=\"desc_len\")\n",
    "    name_len = Input(shape=[1], name=\"name_len\")\n",
    "    subcat_0 = Input(shape=[1], name=\"subcat_0\")\n",
    "    subcat_1 = Input(shape=[1], name=\"subcat_1\")\n",
    "    subcat_2 = Input(shape=[1], name=\"subcat_2\")\n",
    "\n",
    "    # Embeddings layers (adjust outputs to help model)\n",
    "    emb_name = Embedding(MAX_TEXT, 20)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "#     emb_category_name = Embedding(MAX_TEXT, 20)(category_name)\n",
    "#     emb_category = Embedding(MAX_CATEGORY, 10)(category)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    emb_desc_len = Embedding(MAX_DESC_LEN, 5)(desc_len)\n",
    "    emb_name_len = Embedding(MAX_NAME_LEN, 5)(name_len)\n",
    "    emb_subcat_0 = Embedding(MAX_SUBCAT_0, 10)(subcat_0)\n",
    "    emb_subcat_1 = Embedding(MAX_SUBCAT_1, 10)(subcat_1)\n",
    "    emb_subcat_2 = Embedding(MAX_SUBCAT_2, 10)(subcat_2)\n",
    "    \n",
    "\n",
    "    # rnn layers (GRUs are faster than LSTMs and speed is important here)\n",
    "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "#     rnn_layer3 = GRU(8) (emb_category_name)\n",
    "\n",
    "    # main layers\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "#         , Flatten() (emb_category)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , Flatten() (emb_desc_len)\n",
    "        , Flatten() (emb_name_len)\n",
    "        , Flatten() (emb_subcat_0)\n",
    "        , Flatten() (emb_subcat_1)\n",
    "        , Flatten() (emb_subcat_2)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "#         , rnn_layer3\n",
    "        , num_vars\n",
    "    ])\n",
    "    # (incressing the nodes or adding layers does not effect the time quite as much as the rnn layers)\n",
    "    main_l = Dropout(0.1)(Dense(512,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(256,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(128,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(64,kernel_initializer='normal',activation='relu') (main_l))\n",
    "\n",
    "    # the output layer.\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    model = Model([name, item_desc, brand_name , item_condition, \n",
    "                   num_vars, desc_len, name_len, subcat_0, subcat_1, subcat_2], output)\n",
    "\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    # (mean squared error loss function works as well as custom functions)  \n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = new_rnn_model()\n",
    "model.summary()\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file='model.png')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用数据拟合RNN模型并设置超参数\n",
    "最关键的是时间的花销。这将花费35~40分钟去run的RNN！用小的batches的2个epoch的效果比大的batches的更多的epochs要好。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型超参数的设置\n",
    "BATCH_SIZE = 512 * 3\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 计算衰减学习率\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train['name']) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.005, 0.001\n",
    "print(steps)\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1979 samples, validate on 20 samples\n",
      "Epoch 1/2\n",
      "1979/1979 [==============================] - 1s - loss: 9.2770 - val_loss: 7.2270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/2\n",
      "1979/1979 [==============================] - 1s - loss: 8.2325 - val_loss: 6.8630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce2e9e8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建模型并拟合训练集\n",
    "# verbose=1 does is printing a log line after every batch.\n",
    "rnn_model = new_rnn_model(lr=lr_init, decay=lr_decay)\n",
    "rnn_model.fit(\n",
    "        X_train, Y_train, epochs=epochs, batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_dev, Y_dev), verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on validation data...\n",
      " RMSLE error: 2.61973697446\n"
     ]
    }
   ],
   "source": [
    "#用RNN模型评估验证集\n",
    "print(\"Evaluating the model on validation data...\")\n",
    "Y_dev_preds_rnn = rnn_model.predict(X_dev, batch_size=BATCH_SIZE)\n",
    "print(\" RMSLE error:\", rmsle(Y_dev, Y_dev_preds_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "#Make prediction for test data\n",
    "rnn_preds = rnn_model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "rnn_preds = np.expm1(rnn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Now onto the Ridge models. Less to play with in the Ridge models but it is faster than the RNN.\n",
    "# Concatenate train - dev - test data for easy to handle\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>name_len</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>target</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Home/Home Appliances/Vacuums &amp; Floor Care</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Hoover Air Express Handheld Vacuum w...</td>\n",
       "      <td>Hoover Air Express Hand Vacuum</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home Appliances</td>\n",
       "      <td>Vacuums &amp; Floor Care</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Old Navy</td>\n",
       "      <td>Kids/Girls 0-24 Mos/One-Pieces</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirt 0-3 month leggings 6 months old navy and...</td>\n",
       "      <td>Winter bundle</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Girls 0-24 Mos</td>\n",
       "      <td>One-Pieces</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>American Boy &amp; Girl</td>\n",
       "      <td>Kids/Toys/Dolls &amp; Accessories</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Theater case/ Trunk with box.</td>\n",
       "      <td>Marisol Lot HOLD APPLE</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Dolls &amp; Accessories</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand_name                              category_name  \\\n",
       "1503               Hoover  Home/Home Appliances/Vacuums & Floor Care   \n",
       "553              Old Navy             Kids/Girls 0-24 Mos/One-Pieces   \n",
       "775   American Boy & Girl              Kids/Toys/Dolls & Accessories   \n",
       "\n",
       "      desc_len  item_condition_id  \\\n",
       "1503        35                  1   \n",
       "553         10                  2   \n",
       "775          5                  2   \n",
       "\n",
       "                                       item_description  \\\n",
       "1503  Brand New Hoover Air Express Handheld Vacuum w...   \n",
       "553   Shirt 0-3 month leggings 6 months old navy and...   \n",
       "775                       Theater case/ Trunk with box.   \n",
       "\n",
       "                                name  name_len  price  shipping subcat_0  \\\n",
       "1503  Hoover Air Express Hand Vacuum         5   12.0         1     Home   \n",
       "553                    Winter bundle         2    8.0         0     Kids   \n",
       "775           Marisol Lot HOLD APPLE         4   29.0         0     Kids   \n",
       "\n",
       "             subcat_1              subcat_2    target  test_id  train_id  \n",
       "1503  Home Appliances  Vacuums & Floor Care  2.564949      NaN    1503.0  \n",
       "553    Girls 0-24 Mos            One-Pieces  2.197225      NaN     553.0  \n",
       "775              Toys   Dolls & Accessories  3.401197      NaN     775.0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n"
     ]
    }
   ],
   "source": [
    "##Handle missing data and convert data type to string¶\n",
    "##All inputs must be strings in a ridge model. The other note here is that filling NAs for item_description use 'No description yet' so it is read the same as the 'No description yet' entries.\n",
    "print(\"Handling missing values...\")\n",
    "full_df['category_name'] = full_df['category_name'].fillna('missing').astype(str)\n",
    "full_df['subcat_0'] = full_df['subcat_0'].astype(str)\n",
    "full_df['subcat_1'] = full_df['subcat_1'].astype(str)\n",
    "full_df['subcat_2'] = full_df['subcat_2'].astype(str)\n",
    "full_df['brand_name'] = full_df['brand_name'].fillna('missing').astype(str)\n",
    "full_df['shipping'] = full_df['shipping'].astype(str)\n",
    "full_df['item_condition_id'] = full_df['item_condition_id'].astype(str)\n",
    "full_df['desc_len'] = full_df['desc_len'].astype(str)\n",
    "full_df['name_len'] = full_df['name_len'].astype(str)\n",
    "full_df['item_description'] = full_df['item_description'].fillna('No description yet').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2999 entries, 1503 to 999\n",
      "Data columns (total 15 columns):\n",
      "brand_name           2999 non-null object\n",
      "category_name        2999 non-null object\n",
      "desc_len             2999 non-null object\n",
      "item_condition_id    2999 non-null object\n",
      "item_description     2999 non-null object\n",
      "name                 2999 non-null object\n",
      "name_len             2999 non-null object\n",
      "price                1999 non-null float64\n",
      "shipping             2999 non-null object\n",
      "subcat_0             2999 non-null object\n",
      "subcat_1             2999 non-null object\n",
      "subcat_2             2999 non-null object\n",
      "target               1999 non-null float64\n",
      "test_id              1000 non-null float64\n",
      "train_id             1999 non-null float64\n",
      "dtypes: float64(4), object(11)\n",
      "memory usage: 374.9+ KB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing data...\n"
     ]
    }
   ],
   "source": [
    "#Vectorizing all the data\n",
    "##Takes around 8-10 minutes depending on the inputs used.\n",
    "print(\"Vectorizing data...\")\n",
    "default_preprocessor = CountVectorizer().build_preprocessor()\n",
    "def build_preprocessor(field):\n",
    "    field_idx = list(full_df.columns).index(field)\n",
    "    return lambda x: default_preprocessor(x[field_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name</th>\n",
       "      <th>name_len</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>subcat_0</th>\n",
       "      <th>subcat_1</th>\n",
       "      <th>subcat_2</th>\n",
       "      <th>target</th>\n",
       "      <th>test_id</th>\n",
       "      <th>train_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Home/Home Appliances/Vacuums &amp; Floor Care</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand New Hoover Air Express Handheld Vacuum w...</td>\n",
       "      <td>Hoover Air Express Hand Vacuum</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home Appliances</td>\n",
       "      <td>Vacuums &amp; Floor Care</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Old Navy</td>\n",
       "      <td>Kids/Girls 0-24 Mos/One-Pieces</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Shirt 0-3 month leggings 6 months old navy and...</td>\n",
       "      <td>Winter bundle</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Girls 0-24 Mos</td>\n",
       "      <td>One-Pieces</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>American Boy &amp; Girl</td>\n",
       "      <td>Kids/Toys/Dolls &amp; Accessories</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Theater case/ Trunk with box.</td>\n",
       "      <td>Marisol Lot HOLD APPLE</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Dolls &amp; Accessories</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand_name                              category_name desc_len  \\\n",
       "1503               Hoover  Home/Home Appliances/Vacuums & Floor Care       35   \n",
       "553              Old Navy             Kids/Girls 0-24 Mos/One-Pieces       10   \n",
       "775   American Boy & Girl              Kids/Toys/Dolls & Accessories        5   \n",
       "\n",
       "     item_condition_id                                   item_description  \\\n",
       "1503                 1  Brand New Hoover Air Express Handheld Vacuum w...   \n",
       "553                  2  Shirt 0-3 month leggings 6 months old navy and...   \n",
       "775                  2                      Theater case/ Trunk with box.   \n",
       "\n",
       "                                name name_len  price shipping subcat_0  \\\n",
       "1503  Hoover Air Express Hand Vacuum        5   12.0        1     Home   \n",
       "553                    Winter bundle        2    8.0        0     Kids   \n",
       "775           Marisol Lot HOLD APPLE        4   29.0        0     Kids   \n",
       "\n",
       "             subcat_1              subcat_2    target  test_id  train_id  \n",
       "1503  Home Appliances  Vacuums & Floor Care  2.564949      NaN    1503.0  \n",
       "553    Girls 0-24 Mos            One-Pieces  2.197225      NaN     553.0  \n",
       "775              Toys   Dolls & Accessories  3.401197      NaN     775.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bundle                                      5\n",
       "Dress                                       4\n",
       "Boots                                       4\n",
       "Black booties                               2\n",
       "Tommy Hilfiger                              2\n",
       "Giffin 25 rdta full tank kit                2\n",
       "Blouse                                      2\n",
       "Pandora bracelet                            2\n",
       "Kate Spade Wallet                           2\n",
       "Lululemon crops                             2\n",
       "Lularoe OS leggings                         2\n",
       "Michael Kors                                2\n",
       "Coach purse                                 2\n",
       "3 packs frozen gift bundle                  1\n",
       "Gold Tall n Short M8 Lighter Bundle Sale    1\n",
       "NWT VS ULTIMATE SPORTS BRA 34ddd            1\n",
       "Oversized gold circle clear lens glasses    1\n",
       "New boy elf on the shelf ships today        1\n",
       "iPhone 6 64gb Gold (Sprint)                 1\n",
       "???SALE??? JUICY COUTURE TOGGLE NECKLACE    1\n",
       "Off shoulder top L                          1\n",
       "Instrumental Beauty sonic skin brush        1\n",
       "Origins facial treatment sample set         1\n",
       "Boys Asics Wrestling Headgear Head Gear     1\n",
       "PRETTY WHITE SUPER SPARKLY WEDDING RING     1\n",
       "Huf Shirt                                   1\n",
       "FREE SHIP Body Mist                         1\n",
       "New Garfield T-shirt                        1\n",
       "Timberland Boots Sz 8.5 Condition 8/10      1\n",
       "Sperry Top-Sider Boat shoes size 7.5M       1\n",
       "                                           ..\n",
       "NEW!! Men's skinny PRADA tie!               1\n",
       "Lularoe OS destash 2 pair combined          1\n",
       "Home decor                                  1\n",
       "Anastasia lipgloss - sepia                  1\n",
       "Banana Republic Gray Dress, DZ 8            1\n",
       "sleep shorts                                1\n",
       "Lululemon leggings size 6 Blue              1\n",
       "Hand made dress                             1\n",
       "Flamingo PopSocket                          1\n",
       "Nude bodycon dress                          1\n",
       "White Blazzer                               1\n",
       "BumGenius pink and Lovelace pockets         1\n",
       "Nike women's flex size 8.5                  1\n",
       "Victoria Secret Aztec bikini                1\n",
       "3pc tempered glass for iPhone 6 Plus        1\n",
       "Brandy Melville Indian skull crop tank      1\n",
       "Newborn girl holiday dress                  1\n",
       "HERMES authentic men's silk tie             1\n",
       "Bbw lotion                                  1\n",
       "Nike jacket                                 1\n",
       "Men's Ralph Lauren NWOT Polo                1\n",
       "Hold for Engravemybones                     1\n",
       "Glamglow flashmud full size                 1\n",
       "REN, Derma e, it cosmetics, Estée Lauder    1\n",
       "CORAL forever 21 long dress size small      1\n",
       "New shopkins 6 pack of earrings             1\n",
       "Tumblr Stickers: read description           1\n",
       "Reserved for someone                        1\n",
       "FREE SHIP Age Rewind Concealer              1\n",
       "NWT OS Lularoe Disney Leggings              1\n",
       "Name: name, Length: 2979, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pipeline包提供了FeatureUnion类来进行整体并行处理\n",
    "vectorizer = FeatureUnion([\n",
    "    ('name', CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50000,\n",
    "        preprocessor=build_preprocessor('name'))),\n",
    "#     ('category_name', CountVectorizer(\n",
    "#         token_pattern='.+',\n",
    "#         preprocessor=build_preprocessor('category_name'))),\n",
    "    ('subcat_0', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_0'))),\n",
    "    ('subcat_1', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_1'))),\n",
    "    ('subcat_2', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_2'))),\n",
    "    ('brand_name', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('brand_name'))),\n",
    "    ('shipping', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('shipping'))),\n",
    "    ('item_condition_id', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('item_condition_id'))),\n",
    "    ('desc_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('desc_len'))),\n",
    "    ('name_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('name_len'))),\n",
    "    ('item_description', TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_features=100000,\n",
    "        preprocessor=build_preprocessor('item_description'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hoover', 'Home/Home Appliances/Vacuums & Floor Care', '35', ...,\n",
       "        2.5649493574615367, nan, 1503.0],\n",
       "       ['Old Navy', 'Kids/Girls 0-24 Mos/One-Pieces', '10', ...,\n",
       "        2.1972245773362196, nan, 553.0],\n",
       "       ['American Boy & Girl', 'Kids/Toys/Dolls & Accessories', '5', ...,\n",
       "        3.4011973816621555, nan, 775.0],\n",
       "       ..., \n",
       "       ['PINK', \"Women/Women's Handbags/Totes & Shoppers\", '6', ..., nan,\n",
       "        997.0, nan],\n",
       "       ['Funko', 'Kids/Toys/Action Figures & Statues', '7', ..., nan,\n",
       "        998.0, nan],\n",
       "       ['missing', 'Vintage & Collectibles/Trading Cards/Sports', '7', ...,\n",
       "        nan, 999.0, nan]], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999, 112822) (1979, 112822) (20, 112822) (1000, 112822)\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(full_df.values)\n",
    "\n",
    "X_train = X[:n_trains]\n",
    "Y_train = train_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = X[n_trains:n_trains+n_devs]\n",
    "Y_dev = dev_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = X[n_trains+n_devs:]\n",
    "print(X.shape, X_train.shape, X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=[5.0], cv=2, fit_intercept=True, gcv_mode=None,\n",
       "    normalize=False, scoring='neg_mean_squared_error',\n",
       "    store_cv_values=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对训练集拟合ridge模型\n",
    "##有交叉验证的Ridge模型比没有的要好一点，但是即便是最小的两次交叉验证，也依然花费4~5分钟。由于严格时间的限制，如果想要更多次将变得不实际。正常的Ridge回归模型仅仅花费30s.\n",
    "#Training data: \n",
    "##X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "#Target values\n",
    "##y : array-like, shape = [n_samples] or [n_samples, n_targets]\n",
    "#这里输入的是csr稀疏矩阵\n",
    "#solver\n",
    "##'auto' : use svd if n_samples > n_features or when X is a sparse\n",
    "##         matrix, otherwise use eigen\n",
    "##'svd' : force computation via singular value decomposition of X\n",
    "##        (does not work for sparse matrices)\n",
    "##'eigen' : force computation via eigendecomposition of X^T X\n",
    "#normalize : boolean, optional, default False\n",
    "#This parameter is ignored when fit_intercept is set to False. \n",
    "#If True, the regressors X will be normalized before regression by subtracting the mean \n",
    "#and dividing by the l2-norm. \n",
    "#If you wish to standardize, please use sklearn.preprocessing.StandardScaler before calling fit on an estimator with normalize=False.\n",
    "#\n",
    "ridge_model = Ridge(\n",
    "    solver='auto', fit_intercept=True, alpha=1.0,\n",
    "    max_iter=100, normalize=False, tol=0.05, random_state = 1,\n",
    ")\n",
    "ridge_modelCV = RidgeCV(\n",
    "    fit_intercept=True, alphas=[5.0],\n",
    "    normalize=False, cv = 2, scoring='neg_mean_squared_error',\n",
    ")\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "ridge_modelCV.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97646890936611108"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score():The coefficient R^2 is defined as (1 - u/v), \n",
    "#where u is the residual sum of squares ((y_true - y_pred) ** 2).sum()\n",
    "# and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 \n",
    "ridge_model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSL error on dev set: 0.554456598655\n",
      "CV RMSL error on dev set: 0.5674141717\n"
     ]
    }
   ],
   "source": [
    "#在验证集上评估Ridge模型\n",
    "Y_dev_preds_ridge = ridge_model.predict(X_dev)\n",
    "Y_dev_preds_ridge = Y_dev_preds_ridge.reshape(-1, 1)\n",
    "print(\"RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridge))\n",
    "Y_dev_preds_ridgeCV = ridge_modelCV.predict(X_dev)\n",
    "Y_dev_preds_ridgeCV = Y_dev_preds_ridgeCV.reshape(-1, 1)\n",
    "print(\"CV RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridgeCV))\n",
    "#在测试集上做预测\n",
    "\n",
    "ridge_preds = ridge_model.predict(X_test)\n",
    "ridge_preds = np.expm1(ridge_preds)\n",
    "ridgeCV_preds = ridge_modelCV.predict(X_test)\n",
    "ridgeCV_preds = np.expm1(ridgeCV_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 综合几个模型的预测结果，求取各个模型的权重最优的组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n",
      "0.0\n",
      "(Best) RMSL error for RNN + Ridge + RidgeCV on dev set: 0.543152766234\n"
     ]
    }
   ],
   "source": [
    "#在验证集上评估组合起来的模型\n",
    "##组合三个预测结果成一个预测结果。不是简单的求平均，而是综合预测将使用比率来改变3个模型的权重。它还使用一个简单的循环遍历所有可能的比率，以在验证集中找到最佳比例。 它不是计算效率最高的循环，但它只需要2秒就可以运行，所以没什么大不了的。\n",
    "def aggregate_predicts3(Y1, Y2, Y3, ratio1, ratio2):\n",
    "    assert Y1.shape == Y2.shape\n",
    "    return Y1 * ratio1 + Y2 * ratio2 + Y3 * (1.0 - ratio1-ratio2)\n",
    "\n",
    "# Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, 0.4, 0.3)\n",
    "# print(\"RMSL error for RNN + Ridge + RidgeCV on dev set:\", rmsle(Y_dev, Y_dev_preds))\n",
    "#ratio optimum finder for 3 models\n",
    "best1 = 0\n",
    "best2 = 0\n",
    "lowest = 0.99\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        r = i*0.01\n",
    "        r2 = j*0.01\n",
    "        if r+r2 < 1.0:\n",
    "            Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, r, r2)\n",
    "            fpred = rmsle(Y_dev, Y_dev_preds)\n",
    "            if fpred < lowest:\n",
    "                best1 = r\n",
    "                best2 = r2\n",
    "                lowest = fpred\n",
    "#             print(str(r)+\"-RMSL error for RNN + Ridge + RidgeCV on dev set:\", fpred)\n",
    "Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, best1, best2)\n",
    "\n",
    "print(best1)\n",
    "print(best2)\n",
    "print(\"(Best) RMSL error for RNN + Ridge + RidgeCV on dev set:\", rmsle(Y_dev, Y_dev_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将最好的结果写入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best predicted submission\n",
    "preds = aggregate_predicts3(rnn_preds, ridgeCV_preds, ridge_preds, best1, best2)\n",
    "submission = pd.DataFrame({\n",
    "        \"test_id\": test_df.test_id,\n",
    "        \"price\": preds.reshape(-1),\n",
    "})\n",
    "submission.to_csv(\"./rnn_ridge_submission_best.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
